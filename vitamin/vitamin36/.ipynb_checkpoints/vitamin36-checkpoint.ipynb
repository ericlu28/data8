{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: Classifiers\n",
      "OK, version v1.18.1\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('vitamin36.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vitamin 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: Classifiers\n",
      "OK, version v1.18.1\n",
      "=====================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR  | auth.py:102 | {'error': 'invalid_grant'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Open the following URL:\n",
      "\n",
      "https://okpy.org/client/login/\n",
      "\n",
      "After logging in, copy the code from the web page and paste it into the box.\n",
      "Then press the \"Enter\" key on your keyboard.\n",
      "\n",
      "Paste your code here: cIHuX6ecASzd5rNwpkDNejcu8XCsw9\n",
      "Successfully logged in as ealu@berkeley.edu\n"
     ]
    }
   ],
   "source": [
    "# Don't change this cell; just run it. \n",
    "# When you log-in please hit return (not shift + return) after typing in your email\n",
    "from client.api.notebook import *\n",
    "def new_save_notebook(self):\n",
    "    \"\"\" Saves the current notebook by\n",
    "        injecting JavaScript to save to .ipynb file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from IPython.display import display, Javascript\n",
    "    except ImportError:\n",
    "        log.warning(\"Could not import IPython Display Function\")\n",
    "        print(\"Make sure to save your notebook before sending it to OK!\")\n",
    "        return\n",
    "\n",
    "    if self.mode == \"jupyter\":\n",
    "        display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "        display(Javascript('IPython.notebook.save_notebook();'))\n",
    "    elif self.mode == \"jupyterlab\":\n",
    "        display(Javascript('document.querySelector(\\'[data-command=\"docmanager:save\"]\\').click();'))   \n",
    "\n",
    "    print('Saving notebook...', end=' ')\n",
    "\n",
    "    ipynbs = [path for path in self.assignment.src\n",
    "              if os.path.splitext(path)[1] == '.ipynb']\n",
    "    # Wait for first .ipynb to save\n",
    "    if ipynbs:\n",
    "        if wait_for_save(ipynbs[0]):\n",
    "            print(\"Saved '{}'.\".format(ipynbs[0]))\n",
    "        else:\n",
    "            log.warning(\"Timed out waiting for IPython save\")\n",
    "            print(\"Could not automatically save \\'{}\\'\".format(ipynbs[0]))\n",
    "            print(\"Make sure your notebook\"\n",
    "                  \" is correctly named and saved before submitting to OK!\".format(ipynbs[0]))\n",
    "            return False                \n",
    "    else:\n",
    "        print(\"No valid file sources found\")\n",
    "    return True\n",
    "\n",
    "def wait_for_save(filename, timeout=600):\n",
    "    \"\"\"Waits for FILENAME to update, waiting up to TIMEOUT seconds.\n",
    "    Returns True if a save was detected, and False otherwise.\n",
    "    \"\"\"\n",
    "    modification_time = os.path.getmtime(filename)\n",
    "    start_time = time.time()\n",
    "    while time.time() < start_time + timeout:\n",
    "        if (os.path.getmtime(filename) > modification_time and\n",
    "            os.path.getsize(filename) > 0):\n",
    "            return True\n",
    "        time.sleep(0.2)\n",
    "    return False\n",
    "\n",
    "Notebook.save_notebook = new_save_notebook\n",
    "import feedback\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "ok = Notebook('vitamin36.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Some questions have feedback that will guide you to the correct answer, while others will have hidden tests that do not provide feedback. For those that do not have feedback, the `ok.grade` cell will say 100% passed, as long as you put one of the possible choices. **100% passed does not necessarily mean you got the question right!**\n",
    "\n",
    "As long as you watched lecture, you should be able to answer these. If you are stuck, feel free to post on Piazza in the relevant threads!\n",
    "\n",
    "**Deadline**: Vitamin 36 is due Monday (11/23) by 10:59am PST.\n",
    "\n",
    "**Submission**: Once you're finished, select \"Save and Checkpoint\" in the File menu and then run the submit cell at the end. The result will contain a link that you can use to check that your assignment has been submitted successfully. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**A. True or false: To evaluate how accurate a classifier is, we should train it on a dataset, and then evaluate the\n",
    "accuracy of its predictions using the same exact dataset.**\n",
    "1. `True`\n",
    "2. `False`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: qA\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_A = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If we were to evaluate the performance of a classifier using the data on which it was trained, we would end up with overly optimistic results. Instead, we should randomly split our data into a training and a testing set, train the algorithm on the training set, and then evaluate it on the testing set. This will provide us with a more reasonable measure of the classifier's performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 3\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"qA\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**B. True or false? If the attributes used in a nearest neighbors classifier are on very different numerical scales, it is a good idea to standardize the units of these variables before training the algorithm.**\n",
    "\n",
    "1. `True`\n",
    "2. `False`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: qB\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_B = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"qB\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the submit cell to receive credit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
